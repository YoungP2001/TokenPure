{'transformer_blocks.0.attn.processor': MultiDoubleStreamBlockLoraProcessor(
  (q_loras): ModuleList(
    (0): LoRALinearLayer(
      (down): Linear(in_features=3072, out_features=128, bias=False)
      (up): Linear(in_features=128, out_features=3072, bias=False)
    )
  )
  (k_loras): ModuleList(
    (0): LoRALinearLayer(
      (down): Linear(in_features=3072, out_features=128, bias=False)
      (up): Linear(in_features=128, out_features=3072, bias=False)
    )
  )
  (v_loras): ModuleList(
    (0): LoRALinearLayer(
      (down): Linear(in_features=3072, out_features=128, bias=False)
      (up): Linear(in_features=128, out_features=3072, bias=False)
    )
  )
  (proj_loras): ModuleList(
    (0): LoRALinearLayer(
      (down): Linear(in_features=3072, out_features=128, bias=False)
      (up): Linear(in_features=128, out_features=3072, bias=False)
    )
  )
  (to_k_ip): Linear(in_features=4096, out_features=3072, bias=False)
  (to_v_ip): Linear(in_features=4096, out_features=3072, bias=False)
  (norm_added_k): RMSNorm()
),
'transformer_blocks.1.attn.processor': MultiDoubleStreamBlockLoraProcessor(
  (q_loras): ModuleList(
    (0): LoRALinearLayer(
      (down): Linear(in_features=3072, out_features=128, bias=False)
      (up): Linear(in_features=128, out_features=3072, bias=False)
    )
  )
  (k_loras): ModuleList(
    (0): LoRALinearLayer(
      (down): Linear(in_features=3072, out_features=128, bias=False)
      (up): Linear(in_features=128, out_features=3072, bias=False)
    )
  )
  (v_loras): ModuleList(
    (0): LoRALinearLayer(
      (down): Linear(in_features=3072, out_features=128, bias=False)
      (up): Linear(in_features=128, out_features=3072, bias=False)
    )
  )
  (proj_loras): ModuleList(
    (0): LoRALinearLayer(
      (down): Linear(in_features=3072, out_features=128, bias=False)
      (up): Linear(in_features=128, out_features=3072, bias=False)
    )
  )
  (to_k_ip): Linear(in_features=4096, out_features=3072, bias=False)
  (to_v_ip): Linear(in_features=4096, out_features=3072, bias=False)
  (norm_added_k): RMSNorm()
),
'transformer_blocks.2.attn.processor': MultiDoubleStreamBlockLoraProcessor(
  (q_loras): ModuleList(
    (0): LoRALinearLayer(
      (down): Linear(in_features=3072, out_features=128, bias=False)
      (up): Linear(in_features=128, out_features=3072, bias=False)
    )
  )
  (k_loras): ModuleList(
    (0): LoRALinearLayer(
      (down): Linear(in_features=3072, out_features=128, bias=False)
      (up): Linear(in_features=128, out_features=3072, bias=False)
    )
  )
  (v_loras): ModuleList(
    (0): LoRALinearLayer(
      (down): Linear(in_features=3072, out_features=128, bias=False)
      (up): Linear(in_features=128, out_features=3072, bias=False)
    )
  )
  (proj_loras): ModuleList(
    (0): LoRALinearLayer(
      (down): Linear(in_features=3072, out_features=128, bias=False)
      (up): Linear(in_features=128, out_features=3072, bias=False)
    )
  )
  (to_k_ip): Linear(in_features=4096, out_features=3072, bias=False)
  (to_v_ip): Linear(in_features=4096, out_features=3072, bias=False)
  (norm_added_k): RMSNorm()
),
'transformer_blocks.3.attn.processor': MultiDoubleStreamBlockLoraProcessor(
  (q_loras): ModuleList(
    (0): LoRALinearLayer(
      (down): Linear(in_features=3072, out_features=128, bias=False)
      (up): Linear(in_features=128, out_features=3072, bias=False)
    )
  )
  (k_loras): ModuleList(
    (0): LoRALinearLayer(
      (down): Linear(in_features=3072, out_features=128, bias=False)
      (up): Linear(in_features=128, out_features=3072, bias=False)
    )
  )
  (v_loras): ModuleList(
    (0): LoRALinearLayer(
      (down): Linear(in_features=3072, out_features=128, bias=False)
      (up): Linear(in_features=128, out_features=3072, bias=False)
    )
  )
  (proj_loras): ModuleList(
    (0): LoRALinearLayer(
      (down): Linear(in_features=3072, out_features=128, bias=False)
      (up): Linear(in_features=128, out_features=3072, bias=False)
    )
  )
  (to_k_ip): Linear(in_features=4096, out_features=3072, bias=False)
  (to_v_ip): Linear(in_features=4096, out_features=3072, bias=False)
  (norm_added_k): RMSNorm()
), 'transformer_blocks.4.attn.processor': MultiDoubleStreamBlockLoraProcessor(
  (q_loras): ModuleList(
    (0): LoRALinearLayer(
      (down): Linear(in_features=3072, out_features=128, bias=False)
      (up): Linear(in_features=128, out_features=3072, bias=False)
    )
  )
  (k_loras): ModuleList(
    (0): LoRALinearLayer(
      (down): Linear(in_features=3072, out_features=128, bias=False)
      (up): Linear(in_features=128, out_features=3072, bias=False)
    )
  )
  (v_loras): ModuleList(
    (0): LoRALinearLayer(
      (down): Linear(in_features=3072, out_features=128, bias=False)
      (up): Linear(in_features=128, out_features=3072, bias=False)
    )
  )
  (proj_loras): ModuleList(
    (0): LoRALinearLayer(
      (down): Linear(in_features=3072, out_features=128, bias=False)
      (up): Linear(in_features=128, out_features=3072, bias=False)
    )
  )
  (to_k_ip): Linear(in_features=4096, out_features=3072, bias=False)
  (to_v_ip): Linear(in_features=4096, out_features=3072, bias=False)
  (norm_added_k): RMSNorm()
), 'transformer_blocks.5.attn.processor': MultiDoubleStreamBlockLoraProcessor(
  (q_loras): ModuleList(
    (0): LoRALinearLayer(
      (down): Linear(in_features=3072, out_features=128, bias=False)
      (up): Linear(in_features=128, out_features=3072, bias=False)
    )
  )
  (k_loras): ModuleList(
    (0): LoRALinearLayer(
      (down): Linear(in_features=3072, out_features=128, bias=False)
      (up): Linear(in_features=128, out_features=3072, bias=False)
    )
  )
  (v_loras): ModuleList(
    (0): LoRALinearLayer(
      (down): Linear(in_features=3072, out_features=128, bias=False)
      (up): Linear(in_features=128, out_features=3072, bias=False)
    )
  )
  (proj_loras): ModuleList(
    (0): LoRALinearLayer(
      (down): Linear(in_features=3072, out_features=128, bias=False)
      (up): Linear(in_features=128, out_features=3072, bias=False)
    )
  )
  (to_k_ip): Linear(in_features=4096, out_features=3072, bias=False)
  (to_v_ip): Linear(in_features=4096, out_features=3072, bias=False)
  (norm_added_k): RMSNorm()
), 'transformer_blocks.6.attn.processor': MultiDoubleStreamBlockLoraProcessor(
  (q_loras): ModuleList(
    (0): LoRALinearLayer(
      (down): Linear(in_features=3072, out_features=128, bias=False)
      (up): Linear(in_features=128, out_features=3072, bias=False)
    )
  )
  (k_loras): ModuleList(
    (0): LoRALinearLayer(
      (down): Linear(in_features=3072, out_features=128, bias=False)
      (up): Linear(in_features=128, out_features=3072, bias=False)
    )
  )
  (v_loras): ModuleList(
    (0): LoRALinearLayer(
      (down): Linear(in_features=3072, out_features=128, bias=False)
      (up): Linear(in_features=128, out_features=3072, bias=False)
    )
  )
  (proj_loras): ModuleList(
    (0): LoRALinearLayer(
      (down): Linear(in_features=3072, out_features=128, bias=False)
      (up): Linear(in_features=128, out_features=3072, bias=False)
    )
  )
  (to_k_ip): Linear(in_features=4096, out_features=3072, bias=False)
  (to_v_ip): Linear(in_features=4096, out_features=3072, bias=False)
  (norm_added_k): RMSNorm()
), 'transformer_blocks.7.attn.processor': MultiDoubleStreamBlockLoraProcessor(
  (q_loras): ModuleList(
    (0): LoRALinearLayer(
      (down): Linear(in_features=3072, out_features=128, bias=False)
      (up): Linear(in_features=128, out_features=3072, bias=False)
    )
  )
  (k_loras): ModuleList(
    (0): LoRALinearLayer(
      (down): Linear(in_features=3072, out_features=128, bias=False)
      (up): Linear(in_features=128, out_features=3072, bias=False)
    )
  )
  (v_loras): ModuleList(
    (0): LoRALinearLayer(
      (down): Linear(in_features=3072, out_features=128, bias=False)
      (up): Linear(in_features=128, out_features=3072, bias=False)
    )
  )
  (proj_loras): ModuleList(
    (0): LoRALinearLayer(
      (down): Linear(in_features=3072, out_features=128, bias=False)
      (up): Linear(in_features=128, out_features=3072, bias=False)
    )
  )
  (to_k_ip): Linear(in_features=4096, out_features=3072, bias=False)
  (to_v_ip): Linear(in_features=4096, out_features=3072, bias=False)
  (norm_added_k): RMSNorm()
), 'transformer_blocks.8.attn.processor': MultiDoubleStreamBlockLoraProcessor(
  (q_loras): ModuleList(
    (0): LoRALinearLayer(
      (down): Linear(in_features=3072, out_features=128, bias=False)
      (up): Linear(in_features=128, out_features=3072, bias=False)
    )
  )
  (k_loras): ModuleList(
    (0): LoRALinearLayer(
      (down): Linear(in_features=3072, out_features=128, bias=False)
      (up): Linear(in_features=128, out_features=3072, bias=False)
    )
  )
  (v_loras): ModuleList(
    (0): LoRALinearLayer(
      (down): Linear(in_features=3072, out_features=128, bias=False)
      (up): Linear(in_features=128, out_features=3072, bias=False)
    )
  )
  (proj_loras): ModuleList(
    (0): LoRALinearLayer(
      (down): Linear(in_features=3072, out_features=128, bias=False)
      (up): Linear(in_features=128, out_features=3072, bias=False)
    )
  )
  (to_k_ip): Linear(in_features=4096, out_features=3072, bias=False)
  (to_v_ip): Linear(in_features=4096, out_features=3072, bias=False)
  (norm_added_k): RMSNorm()
), 'transformer_blocks.9.attn.processor': MultiDoubleStreamBlockLoraProcessor(
  (q_loras): ModuleList(
    (0): LoRALinearLayer(
      (down): Linear(in_features=3072, out_features=128, bias=False)
      (up): Linear(in_features=128, out_features=3072, bias=False)
    )
  )
  (k_loras): ModuleList(
    (0): LoRALinearLayer(
      (down): Linear(in_features=3072, out_features=128, bias=False)
      (up): Linear(in_features=128, out_features=3072, bias=False)
    )
  )
  (v_loras): ModuleList(
    (0): LoRALinearLayer(
      (down): Linear(in_features=3072, out_features=128, bias=False)
      (up): Linear(in_features=128, out_features=3072, bias=False)
    )
  )
  (proj_loras): ModuleList(
    (0): LoRALinearLayer(
      (down): Linear(in_features=3072, out_features=128, bias=False)
      (up): Linear(in_features=128, out_features=3072, bias=False)
    )
  )
  (to_k_ip): Linear(in_features=4096, out_features=3072, bias=False)
  (to_v_ip): Linear(in_features=4096, out_features=3072, bias=False)
  (norm_added_k): RMSNorm()
), 'transformer_blocks.10.attn.processor': MultiDoubleStreamBlockLoraProcessor(
  (q_loras): ModuleList(
    (0): LoRALinearLayer(
      (down): Linear(in_features=3072, out_features=128, bias=False)
      (up): Linear(in_features=128, out_features=3072, bias=False)
    )
  )
  (k_loras): ModuleList(
    (0): LoRALinearLayer(
      (down): Linear(in_features=3072, out_features=128, bias=False)
      (up): Linear(in_features=128, out_features=3072, bias=False)
    )
  )
  (v_loras): ModuleList(
    (0): LoRALinearLayer(
      (down): Linear(in_features=3072, out_features=128, bias=False)
      (up): Linear(in_features=128, out_features=3072, bias=False)
    )
  )
  (proj_loras): ModuleList(
    (0): LoRALinearLayer(
      (down): Linear(in_features=3072, out_features=128, bias=False)
      (up): Linear(in_features=128, out_features=3072, bias=False)
    )
  )
  (to_k_ip): Linear(in_features=4096, out_features=3072, bias=False)
  (to_v_ip): Linear(in_features=4096, out_features=3072, bias=False)
  (norm_added_k): RMSNorm()
), 'transformer_blocks.11.attn.processor': MultiDoubleStreamBlockLoraProcessor(
  (q_loras): ModuleList(
    (0): LoRALinearLayer(
      (down): Linear(in_features=3072, out_features=128, bias=False)
      (up): Linear(in_features=128, out_features=3072, bias=False)
    )
  )
  (k_loras): ModuleList(
    (0): LoRALinearLayer(
      (down): Linear(in_features=3072, out_features=128, bias=False)
      (up): Linear(in_features=128, out_features=3072, bias=False)
    )
  )
  (v_loras): ModuleList(
    (0): LoRALinearLayer(
      (down): Linear(in_features=3072, out_features=128, bias=False)
      (up): Linear(in_features=128, out_features=3072, bias=False)
    )
  )
  (proj_loras): ModuleList(
    (0): LoRALinearLayer(
      (down): Linear(in_features=3072, out_features=128, bias=False)
      (up): Linear(in_features=128, out_features=3072, bias=False)
    )
  )
  (to_k_ip): Linear(in_features=4096, out_features=3072, bias=False)
  (to_v_ip): Linear(in_features=4096, out_features=3072, bias=False)
  (norm_added_k): RMSNorm()
), 'transformer_blocks.12.attn.processor': MultiDoubleStreamBlockLoraProcessor(
  (q_loras): ModuleList(
    (0): LoRALinearLayer(
      (down): Linear(in_features=3072, out_features=128, bias=False)
      (up): Linear(in_features=128, out_features=3072, bias=False)
    )
  )
  (k_loras): ModuleList(
    (0): LoRALinearLayer(
      (down): Linear(in_features=3072, out_features=128, bias=False)
      (up): Linear(in_features=128, out_features=3072, bias=False)
    )
  )
  (v_loras): ModuleList(
    (0): LoRALinearLayer(
      (down): Linear(in_features=3072, out_features=128, bias=False)
      (up): Linear(in_features=128, out_features=3072, bias=False)
    )
  )
  (proj_loras): ModuleList(
    (0): LoRALinearLayer(
      (down): Linear(in_features=3072, out_features=128, bias=False)
      (up): Linear(in_features=128, out_features=3072, bias=False)
    )
  )
  (to_k_ip): Linear(in_features=4096, out_features=3072, bias=False)
  (to_v_ip): Linear(in_features=4096, out_features=3072, bias=False)
  (norm_added_k): RMSNorm()
), 'transformer_blocks.13.attn.processor': MultiDoubleStreamBlockLoraProcessor(
  (q_loras): ModuleList(
    (0): LoRALinearLayer(
      (down): Linear(in_features=3072, out_features=128, bias=False)
      (up): Linear(in_features=128, out_features=3072, bias=False)
    )
  )
  (k_loras): ModuleList(
    (0): LoRALinearLayer(
      (down): Linear(in_features=3072, out_features=128, bias=False)
      (up): Linear(in_features=128, out_features=3072, bias=False)
    )
  )
  (v_loras): ModuleList(
    (0): LoRALinearLayer(
      (down): Linear(in_features=3072, out_features=128, bias=False)
      (up): Linear(in_features=128, out_features=3072, bias=False)
    )
  )
  (proj_loras): ModuleList(
    (0): LoRALinearLayer(
      (down): Linear(in_features=3072, out_features=128, bias=False)
      (up): Linear(in_features=128, out_features=3072, bias=False)
    )
  )
  (to_k_ip): Linear(in_features=4096, out_features=3072, bias=False)
  (to_v_ip): Linear(in_features=4096, out_features=3072, bias=False)
  (norm_added_k): RMSNorm()
), 'transformer_blocks.14.attn.processor': MultiDoubleStreamBlockLoraProcessor(
  (q_loras): ModuleList(
    (0): LoRALinearLayer(
      (down): Linear(in_features=3072, out_features=128, bias=False)
      (up): Linear(in_features=128, out_features=3072, bias=False)
    )
  )
  (k_loras): ModuleList(
    (0): LoRALinearLayer(
      (down): Linear(in_features=3072, out_features=128, bias=False)
      (up): Linear(in_features=128, out_features=3072, bias=False)
    )
  )
  (v_loras): ModuleList(
    (0): LoRALinearLayer(
      (down): Linear(in_features=3072, out_features=128, bias=False)
      (up): Linear(in_features=128, out_features=3072, bias=False)
    )
  )
  (proj_loras): ModuleList(
    (0): LoRALinearLayer(
      (down): Linear(in_features=3072, out_features=128, bias=False)
      (up): Linear(in_features=128, out_features=3072, bias=False)
    )
  )
  (to_k_ip): Linear(in_features=4096, out_features=3072, bias=False)
  (to_v_ip): Linear(in_features=4096, out_features=3072, bias=False)
  (norm_added_k): RMSNorm()
), 'transformer_blocks.15.attn.processor': MultiDoubleStreamBlockLoraProcessor(
  (q_loras): ModuleList(
    (0): LoRALinearLayer(
      (down): Linear(in_features=3072, out_features=128, bias=False)
      (up): Linear(in_features=128, out_features=3072, bias=False)
    )
  )
  (k_loras): ModuleList(
    (0): LoRALinearLayer(
      (down): Linear(in_features=3072, out_features=128, bias=False)
      (up): Linear(in_features=128, out_features=3072, bias=False)
    )
  )
  (v_loras): ModuleList(
    (0): LoRALinearLayer(
      (down): Linear(in_features=3072, out_features=128, bias=False)
      (up): Linear(in_features=128, out_features=3072, bias=False)
    )
  )
  (proj_loras): ModuleList(
    (0): LoRALinearLayer(
      (down): Linear(in_features=3072, out_features=128, bias=False)
      (up): Linear(in_features=128, out_features=3072, bias=False)
    )
  )
  (to_k_ip): Linear(in_features=4096, out_features=3072, bias=False)
  (to_v_ip): Linear(in_features=4096, out_features=3072, bias=False)
  (norm_added_k): RMSNorm()
), 'transformer_blocks.16.attn.processor': MultiDoubleStreamBlockLoraProcessor(
  (q_loras): ModuleList(
    (0): LoRALinearLayer(
      (down): Linear(in_features=3072, out_features=128, bias=False)
      (up): Linear(in_features=128, out_features=3072, bias=False)
    )
  )
  (k_loras): ModuleList(
    (0): LoRALinearLayer(
      (down): Linear(in_features=3072, out_features=128, bias=False)
      (up): Linear(in_features=128, out_features=3072, bias=False)
    )
  )
  (v_loras): ModuleList(
    (0): LoRALinearLayer(
      (down): Linear(in_features=3072, out_features=128, bias=False)
      (up): Linear(in_features=128, out_features=3072, bias=False)
    )
  )
  (proj_loras): ModuleList(
    (0): LoRALinearLayer(
      (down): Linear(in_features=3072, out_features=128, bias=False)
      (up): Linear(in_features=128, out_features=3072, bias=False)
    )
  )
  (to_k_ip): Linear(in_features=4096, out_features=3072, bias=False)
  (to_v_ip): Linear(in_features=4096, out_features=3072, bias=False)
  (norm_added_k): RMSNorm()
), 'transformer_blocks.17.attn.processor': MultiDoubleStreamBlockLoraProcessor(
  (q_loras): ModuleList(
    (0): LoRALinearLayer(
      (down): Linear(in_features=3072, out_features=128, bias=False)
      (up): Linear(in_features=128, out_features=3072, bias=False)
    )
  )
  (k_loras): ModuleList(
    (0): LoRALinearLayer(
      (down): Linear(in_features=3072, out_features=128, bias=False)
      (up): Linear(in_features=128, out_features=3072, bias=False)
    )
  )
  (v_loras): ModuleList(
    (0): LoRALinearLayer(
      (down): Linear(in_features=3072, out_features=128, bias=False)
      (up): Linear(in_features=128, out_features=3072, bias=False)
    )
  )
  (proj_loras): ModuleList(
    (0): LoRALinearLayer(
      (down): Linear(in_features=3072, out_features=128, bias=False)
      (up): Linear(in_features=128, out_features=3072, bias=False)
    )
  )
  (to_k_ip): Linear(in_features=4096, out_features=3072, bias=False)
  (to_v_ip): Linear(in_features=4096, out_features=3072, bias=False)
  (norm_added_k): RMSNorm()
), 'transformer_blocks.18.attn.processor': MultiDoubleStreamBlockLoraProcessor(
  (q_loras): ModuleList(
    (0): LoRALinearLayer(
      (down): Linear(in_features=3072, out_features=128, bias=False)
      (up): Linear(in_features=128, out_features=3072, bias=False)
    )
  )
  (k_loras): ModuleList(
    (0): LoRALinearLayer(
      (down): Linear(in_features=3072, out_features=128, bias=False)
      (up): Linear(in_features=128, out_features=3072, bias=False)
    )
  )
  (v_loras): ModuleList(
    (0): LoRALinearLayer(
      (down): Linear(in_features=3072, out_features=128, bias=False)
      (up): Linear(in_features=128, out_features=3072, bias=False)
    )
  )
  (proj_loras): ModuleList(
    (0): LoRALinearLayer(
      (down): Linear(in_features=3072, out_features=128, bias=False)
      (up): Linear(in_features=128, out_features=3072, bias=False)
    )
  )
  (to_k_ip): Linear(in_features=4096, out_features=3072, bias=False)
  (to_v_ip): Linear(in_features=4096, out_features=3072, bias=False)
  (norm_added_k): RMSNorm()
), 'single_transformer_blocks.0.attn.processor': MultiSingleStreamBlockLoraProcessor(
  (q_loras): ModuleList(
    (0): LoRALinearLayer(
      (down): Linear(in_features=3072, out_features=128, bias=False)
      (up): Linear(in_features=128, out_features=3072, bias=False)
    )
  )
  (k_loras): ModuleList(
    (0): LoRALinearLayer(
      (down): Linear(in_features=3072, out_features=128, bias=False)
      (up): Linear(in_features=128, out_features=3072, bias=False)
    )
  )
  (v_loras): ModuleList(
    (0): LoRALinearLayer(
      (down): Linear(in_features=3072, out_features=128, bias=False)
      (up): Linear(in_features=128, out_features=3072, bias=False)
    )
  )
  (to_k_ip): Linear(in_features=4096, out_features=3072, bias=False)
  (to_v_ip): Linear(in_features=4096, out_features=3072, bias=False)
  (norm_added_k): RMSNorm()
), 'single_transformer_blocks.1.attn.processor': MultiSingleStreamBlockLoraProcessor(
  (q_loras): ModuleList(
    (0): LoRALinearLayer(
      (down): Linear(in_features=3072, out_features=128, bias=False)
      (up): Linear(in_features=128, out_features=3072, bias=False)
    )
  )
  (k_loras): ModuleList(
    (0): LoRALinearLayer(
      (down): Linear(in_features=3072, out_features=128, bias=False)
      (up): Linear(in_features=128, out_features=3072, bias=False)
    )
  )
  (v_loras): ModuleList(
    (0): LoRALinearLayer(
      (down): Linear(in_features=3072, out_features=128, bias=False)
      (up): Linear(in_features=128, out_features=3072, bias=False)
    )
  )
  (to_k_ip): Linear(in_features=4096, out_features=3072, bias=False)
  (to_v_ip): Linear(in_features=4096, out_features=3072, bias=False)
  (norm_added_k): RMSNorm()
), 'single_transformer_blocks.2.attn.processor': MultiSingleStreamBlockLoraProcessor(
  (q_loras): ModuleList(
    (0): LoRALinearLayer(
      (down): Linear(in_features=3072, out_features=128, bias=False)
      (up): Linear(in_features=128, out_features=3072, bias=False)
    )
  )
  (k_loras): ModuleList(
    (0): LoRALinearLayer(
      (down): Linear(in_features=3072, out_features=128, bias=False)
      (up): Linear(in_features=128, out_features=3072, bias=False)
    )
  )
  (v_loras): ModuleList(
    (0): LoRALinearLayer(
      (down): Linear(in_features=3072, out_features=128, bias=False)
      (up): Linear(in_features=128, out_features=3072, bias=False)
    )
  )
  (to_k_ip): Linear(in_features=4096, out_features=3072, bias=False)
  (to_v_ip): Linear(in_features=4096, out_features=3072, bias=False)
  (norm_added_k): RMSNorm()
), 'single_transformer_blocks.3.attn.processor': MultiSingleStreamBlockLoraProcessor(
  (q_loras): ModuleList(
    (0): LoRALinearLayer(
      (down): Linear(in_features=3072, out_features=128, bias=False)
      (up): Linear(in_features=128, out_features=3072, bias=False)
    )
  )
  (k_loras): ModuleList(
    (0): LoRALinearLayer(
      (down): Linear(in_features=3072, out_features=128, bias=False)
      (up): Linear(in_features=128, out_features=3072, bias=False)
    )
  )
  (v_loras): ModuleList(
    (0): LoRALinearLayer(
      (down): Linear(in_features=3072, out_features=128, bias=False)
      (up): Linear(in_features=128, out_features=3072, bias=False)
    )
  )
  (to_k_ip): Linear(in_features=4096, out_features=3072, bias=False)
  (to_v_ip): Linear(in_features=4096, out_features=3072, bias=False)
  (norm_added_k): RMSNorm()
), 'single_transformer_blocks.4.attn.processor': MultiSingleStreamBlockLoraProcessor(
  (q_loras): ModuleList(
    (0): LoRALinearLayer(
      (down): Linear(in_features=3072, out_features=128, bias=False)
      (up): Linear(in_features=128, out_features=3072, bias=False)
    )
  )
  (k_loras): ModuleList(
    (0): LoRALinearLayer(
      (down): Linear(in_features=3072, out_features=128, bias=False)
      (up): Linear(in_features=128, out_features=3072, bias=False)
    )
  )
  (v_loras): ModuleList(
    (0): LoRALinearLayer(
      (down): Linear(in_features=3072, out_features=128, bias=False)
      (up): Linear(in_features=128, out_features=3072, bias=False)
    )
  )
  (to_k_ip): Linear(in_features=4096, out_features=3072, bias=False)
  (to_v_ip): Linear(in_features=4096, out_features=3072, bias=False)
  (norm_added_k): RMSNorm()
), 'single_transformer_blocks.5.attn.processor': MultiSingleStreamBlockLoraProcessor(
  (q_loras): ModuleList(
    (0): LoRALinearLayer(
      (down): Linear(in_features=3072, out_features=128, bias=False)
      (up): Linear(in_features=128, out_features=3072, bias=False)
    )
  )
  (k_loras): ModuleList(
    (0): LoRALinearLayer(
      (down): Linear(in_features=3072, out_features=128, bias=False)
      (up): Linear(in_features=128, out_features=3072, bias=False)
    )
  )
  (v_loras): ModuleList(
    (0): LoRALinearLayer(
      (down): Linear(in_features=3072, out_features=128, bias=False)
      (up): Linear(in_features=128, out_features=3072, bias=False)
    )
  )
  (to_k_ip): Linear(in_features=4096, out_features=3072, bias=False)
  (to_v_ip): Linear(in_features=4096, out_features=3072, bias=False)
  (norm_added_k): RMSNorm()
), 'single_transformer_blocks.6.attn.processor': MultiSingleStreamBlockLoraProcessor(
  (q_loras): ModuleList(
    (0): LoRALinearLayer(
      (down): Linear(in_features=3072, out_features=128, bias=False)
      (up): Linear(in_features=128, out_features=3072, bias=False)
    )
  )
  (k_loras): ModuleList(
    (0): LoRALinearLayer(
      (down): Linear(in_features=3072, out_features=128, bias=False)
      (up): Linear(in_features=128, out_features=3072, bias=False)
    )
  )
  (v_loras): ModuleList(
    (0): LoRALinearLayer(
      (down): Linear(in_features=3072, out_features=128, bias=False)
      (up): Linear(in_features=128, out_features=3072, bias=False)
    )
  )
  (to_k_ip): Linear(in_features=4096, out_features=3072, bias=False)
  (to_v_ip): Linear(in_features=4096, out_features=3072, bias=False)
  (norm_added_k): RMSNorm()
), 'single_transformer_blocks.7.attn.processor': MultiSingleStreamBlockLoraProcessor(
  (q_loras): ModuleList(
    (0): LoRALinearLayer(
      (down): Linear(in_features=3072, out_features=128, bias=False)
      (up): Linear(in_features=128, out_features=3072, bias=False)
    )
  )
  (k_loras): ModuleList(
    (0): LoRALinearLayer(
      (down): Linear(in_features=3072, out_features=128, bias=False)
      (up): Linear(in_features=128, out_features=3072, bias=False)
    )
  )
  (v_loras): ModuleList(
    (0): LoRALinearLayer(
      (down): Linear(in_features=3072, out_features=128, bias=False)
      (up): Linear(in_features=128, out_features=3072, bias=False)
    )
  )
  (to_k_ip): Linear(in_features=4096, out_features=3072, bias=False)
  (to_v_ip): Linear(in_features=4096, out_features=3072, bias=False)
  (norm_added_k): RMSNorm()
), 'single_transformer_blocks.8.attn.processor': MultiSingleStreamBlockLoraProcessor(
  (q_loras): ModuleList(
    (0): LoRALinearLayer(
      (down): Linear(in_features=3072, out_features=128, bias=False)
      (up): Linear(in_features=128, out_features=3072, bias=False)
    )
  )
  (k_loras): ModuleList(
    (0): LoRALinearLayer(
      (down): Linear(in_features=3072, out_features=128, bias=False)
      (up): Linear(in_features=128, out_features=3072, bias=False)
    )
  )
  (v_loras): ModuleList(
    (0): LoRALinearLayer(
      (down): Linear(in_features=3072, out_features=128, bias=False)
      (up): Linear(in_features=128, out_features=3072, bias=False)
    )
  )
  (to_k_ip): Linear(in_features=4096, out_features=3072, bias=False)
  (to_v_ip): Linear(in_features=4096, out_features=3072, bias=False)
  (norm_added_k): RMSNorm()
), 'single_transformer_blocks.9.attn.processor': MultiSingleStreamBlockLoraProcessor(
  (q_loras): ModuleList(
    (0): LoRALinearLayer(
      (down): Linear(in_features=3072, out_features=128, bias=False)
      (up): Linear(in_features=128, out_features=3072, bias=False)
    )
  )
  (k_loras): ModuleList(
    (0): LoRALinearLayer(
      (down): Linear(in_features=3072, out_features=128, bias=False)
      (up): Linear(in_features=128, out_features=3072, bias=False)
    )
  )
  (v_loras): ModuleList(
    (0): LoRALinearLayer(
      (down): Linear(in_features=3072, out_features=128, bias=False)
      (up): Linear(in_features=128, out_features=3072, bias=False)
    )
  )
  (to_k_ip): Linear(in_features=4096, out_features=3072, bias=False)
  (to_v_ip): Linear(in_features=4096, out_features=3072, bias=False)
  (norm_added_k): RMSNorm()
), 'single_transformer_blocks.10.attn.processor': MultiSingleStreamBlockLoraProcessor(
  (q_loras): ModuleList(
    (0): LoRALinearLayer(
      (down): Linear(in_features=3072, out_features=128, bias=False)
      (up): Linear(in_features=128, out_features=3072, bias=False)
    )
  )
  (k_loras): ModuleList(
    (0): LoRALinearLayer(
      (down): Linear(in_features=3072, out_features=128, bias=False)
      (up): Linear(in_features=128, out_features=3072, bias=False)
    )
  )
  (v_loras): ModuleList(
    (0): LoRALinearLayer(
      (down): Linear(in_features=3072, out_features=128, bias=False)
      (up): Linear(in_features=128, out_features=3072, bias=False)
    )
  )
  (to_k_ip): Linear(in_features=4096, out_features=3072, bias=False)
  (to_v_ip): Linear(in_features=4096, out_features=3072, bias=False)
  (norm_added_k): RMSNorm()
), 'single_transformer_blocks.11.attn.processor': MultiSingleStreamBlockLoraProcessor(
  (q_loras): ModuleList(
    (0): LoRALinearLayer(
      (down): Linear(in_features=3072, out_features=128, bias=False)
      (up): Linear(in_features=128, out_features=3072, bias=False)
    )
  )
  (k_loras): ModuleList(
    (0): LoRALinearLayer(
      (down): Linear(in_features=3072, out_features=128, bias=False)
      (up): Linear(in_features=128, out_features=3072, bias=False)
    )
  )
  (v_loras): ModuleList(
    (0): LoRALinearLayer(
      (down): Linear(in_features=3072, out_features=128, bias=False)
      (up): Linear(in_features=128, out_features=3072, bias=False)
    )
  )
  (to_k_ip): Linear(in_features=4096, out_features=3072, bias=False)
  (to_v_ip): Linear(in_features=4096, out_features=3072, bias=False)
  (norm_added_k): RMSNorm()
), 'single_transformer_blocks.12.attn.processor': MultiSingleStreamBlockLoraProcessor(
  (q_loras): ModuleList(
    (0): LoRALinearLayer(
      (down): Linear(in_features=3072, out_features=128, bias=False)
      (up): Linear(in_features=128, out_features=3072, bias=False)
    )
  )
  (k_loras): ModuleList(
    (0): LoRALinearLayer(
      (down): Linear(in_features=3072, out_features=128, bias=False)
      (up): Linear(in_features=128, out_features=3072, bias=False)
    )
  )
  (v_loras): ModuleList(
    (0): LoRALinearLayer(
      (down): Linear(in_features=3072, out_features=128, bias=False)
      (up): Linear(in_features=128, out_features=3072, bias=False)
    )
  )
  (to_k_ip): Linear(in_features=4096, out_features=3072, bias=False)
  (to_v_ip): Linear(in_features=4096, out_features=3072, bias=False)
  (norm_added_k): RMSNorm()
), 'single_transformer_blocks.13.attn.processor': MultiSingleStreamBlockLoraProcessor(
  (q_loras): ModuleList(
    (0): LoRALinearLayer(
      (down): Linear(in_features=3072, out_features=128, bias=False)
      (up): Linear(in_features=128, out_features=3072, bias=False)
    )
  )
  (k_loras): ModuleList(
    (0): LoRALinearLayer(
      (down): Linear(in_features=3072, out_features=128, bias=False)
      (up): Linear(in_features=128, out_features=3072, bias=False)
    )
  )
  (v_loras): ModuleList(
    (0): LoRALinearLayer(
      (down): Linear(in_features=3072, out_features=128, bias=False)
      (up): Linear(in_features=128, out_features=3072, bias=False)
    )
  )
  (to_k_ip): Linear(in_features=4096, out_features=3072, bias=False)
  (to_v_ip): Linear(in_features=4096, out_features=3072, bias=False)
  (norm_added_k): RMSNorm()
), 'single_transformer_blocks.14.attn.processor': MultiSingleStreamBlockLoraProcessor(
  (q_loras): ModuleList(
    (0): LoRALinearLayer(
      (down): Linear(in_features=3072, out_features=128, bias=False)
      (up): Linear(in_features=128, out_features=3072, bias=False)
    )
  )
  (k_loras): ModuleList(
    (0): LoRALinearLayer(
      (down): Linear(in_features=3072, out_features=128, bias=False)
      (up): Linear(in_features=128, out_features=3072, bias=False)
    )
  )
  (v_loras): ModuleList(
    (0): LoRALinearLayer(
      (down): Linear(in_features=3072, out_features=128, bias=False)
      (up): Linear(in_features=128, out_features=3072, bias=False)
    )
  )
  (to_k_ip): Linear(in_features=4096, out_features=3072, bias=False)
  (to_v_ip): Linear(in_features=4096, out_features=3072, bias=False)
  (norm_added_k): RMSNorm()
), 'single_transformer_blocks.15.attn.processor': MultiSingleStreamBlockLoraProcessor(
  (q_loras): ModuleList(
    (0): LoRALinearLayer(
      (down): Linear(in_features=3072, out_features=128, bias=False)
      (up): Linear(in_features=128, out_features=3072, bias=False)
    )
  )
  (k_loras): ModuleList(
    (0): LoRALinearLayer(
      (down): Linear(in_features=3072, out_features=128, bias=False)
      (up): Linear(in_features=128, out_features=3072, bias=False)
    )
  )
  (v_loras): ModuleList(
    (0): LoRALinearLayer(
      (down): Linear(in_features=3072, out_features=128, bias=False)
      (up): Linear(in_features=128, out_features=3072, bias=False)
    )
  )
  (to_k_ip): Linear(in_features=4096, out_features=3072, bias=False)
  (to_v_ip): Linear(in_features=4096, out_features=3072, bias=False)
  (norm_added_k): RMSNorm()
), 'single_transformer_blocks.16.attn.processor': MultiSingleStreamBlockLoraProcessor(
  (q_loras): ModuleList(
    (0): LoRALinearLayer(
      (down): Linear(in_features=3072, out_features=128, bias=False)
      (up): Linear(in_features=128, out_features=3072, bias=False)
    )
  )
  (k_loras): ModuleList(
    (0): LoRALinearLayer(
      (down): Linear(in_features=3072, out_features=128, bias=False)
      (up): Linear(in_features=128, out_features=3072, bias=False)
    )
  )
  (v_loras): ModuleList(
    (0): LoRALinearLayer(
      (down): Linear(in_features=3072, out_features=128, bias=False)
      (up): Linear(in_features=128, out_features=3072, bias=False)
    )
  )
  (to_k_ip): Linear(in_features=4096, out_features=3072, bias=False)
  (to_v_ip): Linear(in_features=4096, out_features=3072, bias=False)
  (norm_added_k): RMSNorm()
), 'single_transformer_blocks.17.attn.processor': MultiSingleStreamBlockLoraProcessor(
  (q_loras): ModuleList(
    (0): LoRALinearLayer(
      (down): Linear(in_features=3072, out_features=128, bias=False)
      (up): Linear(in_features=128, out_features=3072, bias=False)
    )
  )
  (k_loras): ModuleList(
    (0): LoRALinearLayer(
      (down): Linear(in_features=3072, out_features=128, bias=False)
      (up): Linear(in_features=128, out_features=3072, bias=False)
    )
  )
  (v_loras): ModuleList(
    (0): LoRALinearLayer(
      (down): Linear(in_features=3072, out_features=128, bias=False)
      (up): Linear(in_features=128, out_features=3072, bias=False)
    )
  )
  (to_k_ip): Linear(in_features=4096, out_features=3072, bias=False)
  (to_v_ip): Linear(in_features=4096, out_features=3072, bias=False)
  (norm_added_k): RMSNorm()
), 'single_transformer_blocks.18.attn.processor': MultiSingleStreamBlockLoraProcessor(
  (q_loras): ModuleList(
    (0): LoRALinearLayer(
      (down): Linear(in_features=3072, out_features=128, bias=False)
      (up): Linear(in_features=128, out_features=3072, bias=False)
    )
  )
  (k_loras): ModuleList(
    (0): LoRALinearLayer(
      (down): Linear(in_features=3072, out_features=128, bias=False)
      (up): Linear(in_features=128, out_features=3072, bias=False)
    )
  )
  (v_loras): ModuleList(
    (0): LoRALinearLayer(
      (down): Linear(in_features=3072, out_features=128, bias=False)
      (up): Linear(in_features=128, out_features=3072, bias=False)
    )
  )
  (to_k_ip): Linear(in_features=4096, out_features=3072, bias=False)
  (to_v_ip): Linear(in_features=4096, out_features=3072, bias=False)
  (norm_added_k): RMSNorm()
), 'single_transformer_blocks.19.attn.processor': MultiSingleStreamBlockLoraProcessor(
  (q_loras): ModuleList(
    (0): LoRALinearLayer(
      (down): Linear(in_features=3072, out_features=128, bias=False)
      (up): Linear(in_features=128, out_features=3072, bias=False)
    )
  )
  (k_loras): ModuleList(
    (0): LoRALinearLayer(
      (down): Linear(in_features=3072, out_features=128, bias=False)
      (up): Linear(in_features=128, out_features=3072, bias=False)
    )
  )
  (v_loras): ModuleList(
    (0): LoRALinearLayer(
      (down): Linear(in_features=3072, out_features=128, bias=False)
      (up): Linear(in_features=128, out_features=3072, bias=False)
    )
  )
  (to_k_ip): Linear(in_features=4096, out_features=3072, bias=False)
  (to_v_ip): Linear(in_features=4096, out_features=3072, bias=False)
  (norm_added_k): RMSNorm()
), 'single_transformer_blocks.20.attn.processor': MultiSingleStreamBlockLoraProcessor(
  (q_loras): ModuleList(
    (0): LoRALinearLayer(
      (down): Linear(in_features=3072, out_features=128, bias=False)
      (up): Linear(in_features=128, out_features=3072, bias=False)
    )
  )
  (k_loras): ModuleList(
    (0): LoRALinearLayer(
      (down): Linear(in_features=3072, out_features=128, bias=False)
      (up): Linear(in_features=128, out_features=3072, bias=False)
    )
  )
  (v_loras): ModuleList(
    (0): LoRALinearLayer(
      (down): Linear(in_features=3072, out_features=128, bias=False)
      (up): Linear(in_features=128, out_features=3072, bias=False)
    )
  )
  (to_k_ip): Linear(in_features=4096, out_features=3072, bias=False)
  (to_v_ip): Linear(in_features=4096, out_features=3072, bias=False)
  (norm_added_k): RMSNorm()
), 'single_transformer_blocks.21.attn.processor': MultiSingleStreamBlockLoraProcessor(
  (q_loras): ModuleList(
    (0): LoRALinearLayer(
      (down): Linear(in_features=3072, out_features=128, bias=False)
      (up): Linear(in_features=128, out_features=3072, bias=False)
    )
  )
  (k_loras): ModuleList(
    (0): LoRALinearLayer(
      (down): Linear(in_features=3072, out_features=128, bias=False)
      (up): Linear(in_features=128, out_features=3072, bias=False)
    )
  )
  (v_loras): ModuleList(
    (0): LoRALinearLayer(
      (down): Linear(in_features=3072, out_features=128, bias=False)
      (up): Linear(in_features=128, out_features=3072, bias=False)
    )
  )
  (to_k_ip): Linear(in_features=4096, out_features=3072, bias=False)
  (to_v_ip): Linear(in_features=4096, out_features=3072, bias=False)
  (norm_added_k): RMSNorm()
), 'single_transformer_blocks.22.attn.processor': MultiSingleStreamBlockLoraProcessor(
  (q_loras): ModuleList(
    (0): LoRALinearLayer(
      (down): Linear(in_features=3072, out_features=128, bias=False)
      (up): Linear(in_features=128, out_features=3072, bias=False)
    )
  )
  (k_loras): ModuleList(
    (0): LoRALinearLayer(
      (down): Linear(in_features=3072, out_features=128, bias=False)
      (up): Linear(in_features=128, out_features=3072, bias=False)
    )
  )
  (v_loras): ModuleList(
    (0): LoRALinearLayer(
      (down): Linear(in_features=3072, out_features=128, bias=False)
      (up): Linear(in_features=128, out_features=3072, bias=False)
    )
  )
  (to_k_ip): Linear(in_features=4096, out_features=3072, bias=False)
  (to_v_ip): Linear(in_features=4096, out_features=3072, bias=False)
  (norm_added_k): RMSNorm()
), 'single_transformer_blocks.23.attn.processor': MultiSingleStreamBlockLoraProcessor(
  (q_loras): ModuleList(
    (0): LoRALinearLayer(
      (down): Linear(in_features=3072, out_features=128, bias=False)
      (up): Linear(in_features=128, out_features=3072, bias=False)
    )
  )
  (k_loras): ModuleList(
    (0): LoRALinearLayer(
      (down): Linear(in_features=3072, out_features=128, bias=False)
      (up): Linear(in_features=128, out_features=3072, bias=False)
    )
  )
  (v_loras): ModuleList(
    (0): LoRALinearLayer(
      (down): Linear(in_features=3072, out_features=128, bias=False)
      (up): Linear(in_features=128, out_features=3072, bias=False)
    )
  )
  (to_k_ip): Linear(in_features=4096, out_features=3072, bias=False)
  (to_v_ip): Linear(in_features=4096, out_features=3072, bias=False)
  (norm_added_k): RMSNorm()
), 'single_transformer_blocks.24.attn.processor': MultiSingleStreamBlockLoraProcessor(
  (q_loras): ModuleList(
    (0): LoRALinearLayer(
      (down): Linear(in_features=3072, out_features=128, bias=False)
      (up): Linear(in_features=128, out_features=3072, bias=False)
    )
  )
  (k_loras): ModuleList(
    (0): LoRALinearLayer(
      (down): Linear(in_features=3072, out_features=128, bias=False)
      (up): Linear(in_features=128, out_features=3072, bias=False)
    )
  )
  (v_loras): ModuleList(
    (0): LoRALinearLayer(
      (down): Linear(in_features=3072, out_features=128, bias=False)
      (up): Linear(in_features=128, out_features=3072, bias=False)
    )
  )
  (to_k_ip): Linear(in_features=4096, out_features=3072, bias=False)
  (to_v_ip): Linear(in_features=4096, out_features=3072, bias=False)
  (norm_added_k): RMSNorm()
), 'single_transformer_blocks.25.attn.processor': MultiSingleStreamBlockLoraProcessor(
  (q_loras): ModuleList(
    (0): LoRALinearLayer(
      (down): Linear(in_features=3072, out_features=128, bias=False)
      (up): Linear(in_features=128, out_features=3072, bias=False)
    )
  )
  (k_loras): ModuleList(
    (0): LoRALinearLayer(
      (down): Linear(in_features=3072, out_features=128, bias=False)
      (up): Linear(in_features=128, out_features=3072, bias=False)
    )
  )
  (v_loras): ModuleList(
    (0): LoRALinearLayer(
      (down): Linear(in_features=3072, out_features=128, bias=False)
      (up): Linear(in_features=128, out_features=3072, bias=False)
    )
  )
  (to_k_ip): Linear(in_features=4096, out_features=3072, bias=False)
  (to_v_ip): Linear(in_features=4096, out_features=3072, bias=False)
  (norm_added_k): RMSNorm()
), 'single_transformer_blocks.26.attn.processor': MultiSingleStreamBlockLoraProcessor(
  (q_loras): ModuleList(
    (0): LoRALinearLayer(
      (down): Linear(in_features=3072, out_features=128, bias=False)
      (up): Linear(in_features=128, out_features=3072, bias=False)
    )
  )
  (k_loras): ModuleList(
    (0): LoRALinearLayer(
      (down): Linear(in_features=3072, out_features=128, bias=False)
      (up): Linear(in_features=128, out_features=3072, bias=False)
    )
  )
  (v_loras): ModuleList(
    (0): LoRALinearLayer(
      (down): Linear(in_features=3072, out_features=128, bias=False)
      (up): Linear(in_features=128, out_features=3072, bias=False)
    )
  )
  (to_k_ip): Linear(in_features=4096, out_features=3072, bias=False)
  (to_v_ip): Linear(in_features=4096, out_features=3072, bias=False)
  (norm_added_k): RMSNorm()
), 'single_transformer_blocks.27.attn.processor': MultiSingleStreamBlockLoraProcessor(
  (q_loras): ModuleList(
    (0): LoRALinearLayer(
      (down): Linear(in_features=3072, out_features=128, bias=False)
      (up): Linear(in_features=128, out_features=3072, bias=False)
    )
  )
  (k_loras): ModuleList(
    (0): LoRALinearLayer(
      (down): Linear(in_features=3072, out_features=128, bias=False)
      (up): Linear(in_features=128, out_features=3072, bias=False)
    )
  )
  (v_loras): ModuleList(
    (0): LoRALinearLayer(
      (down): Linear(in_features=3072, out_features=128, bias=False)
      (up): Linear(in_features=128, out_features=3072, bias=False)
    )
  )
  (to_k_ip): Linear(in_features=4096, out_features=3072, bias=False)
  (to_v_ip): Linear(in_features=4096, out_features=3072, bias=False)
  (norm_added_k): RMSNorm()
), 'single_transformer_blocks.28.attn.processor': MultiSingleStreamBlockLoraProcessor(
  (q_loras): ModuleList(
    (0): LoRALinearLayer(
      (down): Linear(in_features=3072, out_features=128, bias=False)
      (up): Linear(in_features=128, out_features=3072, bias=False)
    )
  )
  (k_loras): ModuleList(
    (0): LoRALinearLayer(
      (down): Linear(in_features=3072, out_features=128, bias=False)
      (up): Linear(in_features=128, out_features=3072, bias=False)
    )
  )
  (v_loras): ModuleList(
    (0): LoRALinearLayer(
      (down): Linear(in_features=3072, out_features=128, bias=False)
      (up): Linear(in_features=128, out_features=3072, bias=False)
    )
  )
  (to_k_ip): Linear(in_features=4096, out_features=3072, bias=False)
  (to_v_ip): Linear(in_features=4096, out_features=3072, bias=False)
  (norm_added_k): RMSNorm()
), 'single_transformer_blocks.29.attn.processor': MultiSingleStreamBlockLoraProcessor(
  (q_loras): ModuleList(
    (0): LoRALinearLayer(
      (down): Linear(in_features=3072, out_features=128, bias=False)
      (up): Linear(in_features=128, out_features=3072, bias=False)
    )
  )
  (k_loras): ModuleList(
    (0): LoRALinearLayer(
      (down): Linear(in_features=3072, out_features=128, bias=False)
      (up): Linear(in_features=128, out_features=3072, bias=False)
    )
  )
  (v_loras): ModuleList(
    (0): LoRALinearLayer(
      (down): Linear(in_features=3072, out_features=128, bias=False)
      (up): Linear(in_features=128, out_features=3072, bias=False)
    )
  )
  (to_k_ip): Linear(in_features=4096, out_features=3072, bias=False)
  (to_v_ip): Linear(in_features=4096, out_features=3072, bias=False)
  (norm_added_k): RMSNorm()
), 'single_transformer_blocks.30.attn.processor': MultiSingleStreamBlockLoraProcessor(
  (q_loras): ModuleList(
    (0): LoRALinearLayer(
      (down): Linear(in_features=3072, out_features=128, bias=False)
      (up): Linear(in_features=128, out_features=3072, bias=False)
    )
  )
  (k_loras): ModuleList(
    (0): LoRALinearLayer(
      (down): Linear(in_features=3072, out_features=128, bias=False)
      (up): Linear(in_features=128, out_features=3072, bias=False)
    )
  )
  (v_loras): ModuleList(
    (0): LoRALinearLayer(
      (down): Linear(in_features=3072, out_features=128, bias=False)
      (up): Linear(in_features=128, out_features=3072, bias=False)
    )
  )
  (to_k_ip): Linear(in_features=4096, out_features=3072, bias=False)
  (to_v_ip): Linear(in_features=4096, out_features=3072, bias=False)
  (norm_added_k): RMSNorm()
), 'single_transformer_blocks.31.attn.processor': MultiSingleStreamBlockLoraProcessor(
  (q_loras): ModuleList(
    (0): LoRALinearLayer(
      (down): Linear(in_features=3072, out_features=128, bias=False)
      (up): Linear(in_features=128, out_features=3072, bias=False)
    )
  )
  (k_loras): ModuleList(
    (0): LoRALinearLayer(
      (down): Linear(in_features=3072, out_features=128, bias=False)
      (up): Linear(in_features=128, out_features=3072, bias=False)
    )
  )
  (v_loras): ModuleList(
    (0): LoRALinearLayer(
      (down): Linear(in_features=3072, out_features=128, bias=False)
      (up): Linear(in_features=128, out_features=3072, bias=False)
    )
  )
  (to_k_ip): Linear(in_features=4096, out_features=3072, bias=False)
  (to_v_ip): Linear(in_features=4096, out_features=3072, bias=False)
  (norm_added_k): RMSNorm()
), 'single_transformer_blocks.32.attn.processor': MultiSingleStreamBlockLoraProcessor(
  (q_loras): ModuleList(
    (0): LoRALinearLayer(
      (down): Linear(in_features=3072, out_features=128, bias=False)
      (up): Linear(in_features=128, out_features=3072, bias=False)
    )
  )
  (k_loras): ModuleList(
    (0): LoRALinearLayer(
      (down): Linear(in_features=3072, out_features=128, bias=False)
      (up): Linear(in_features=128, out_features=3072, bias=False)
    )
  )
  (v_loras): ModuleList(
    (0): LoRALinearLayer(
      (down): Linear(in_features=3072, out_features=128, bias=False)
      (up): Linear(in_features=128, out_features=3072, bias=False)
    )
  )
  (to_k_ip): Linear(in_features=4096, out_features=3072, bias=False)
  (to_v_ip): Linear(in_features=4096, out_features=3072, bias=False)
  (norm_added_k): RMSNorm()
), 'single_transformer_blocks.33.attn.processor': MultiSingleStreamBlockLoraProcessor(
  (q_loras): ModuleList(
    (0): LoRALinearLayer(
      (down): Linear(in_features=3072, out_features=128, bias=False)
      (up): Linear(in_features=128, out_features=3072, bias=False)
    )
  )
  (k_loras): ModuleList(
    (0): LoRALinearLayer(
      (down): Linear(in_features=3072, out_features=128, bias=False)
      (up): Linear(in_features=128, out_features=3072, bias=False)
    )
  )
  (v_loras): ModuleList(
    (0): LoRALinearLayer(
      (down): Linear(in_features=3072, out_features=128, bias=False)
      (up): Linear(in_features=128, out_features=3072, bias=False)
    )
  )
  (to_k_ip): Linear(in_features=4096, out_features=3072, bias=False)
  (to_v_ip): Linear(in_features=4096, out_features=3072, bias=False)
  (norm_added_k): RMSNorm()
), 'single_transformer_blocks.34.attn.processor': MultiSingleStreamBlockLoraProcessor(
  (q_loras): ModuleList(
    (0): LoRALinearLayer(
      (down): Linear(in_features=3072, out_features=128, bias=False)
      (up): Linear(in_features=128, out_features=3072, bias=False)
    )
  )
  (k_loras): ModuleList(
    (0): LoRALinearLayer(
      (down): Linear(in_features=3072, out_features=128, bias=False)
      (up): Linear(in_features=128, out_features=3072, bias=False)
    )
  )
  (v_loras): ModuleList(
    (0): LoRALinearLayer(
      (down): Linear(in_features=3072, out_features=128, bias=False)
      (up): Linear(in_features=128, out_features=3072, bias=False)
    )
  )
  (to_k_ip): Linear(in_features=4096, out_features=3072, bias=False)
  (to_v_ip): Linear(in_features=4096, out_features=3072, bias=False)
  (norm_added_k): RMSNorm()
), 'single_transformer_blocks.35.attn.processor': MultiSingleStreamBlockLoraProcessor(
  (q_loras): ModuleList(
    (0): LoRALinearLayer(
      (down): Linear(in_features=3072, out_features=128, bias=False)
      (up): Linear(in_features=128, out_features=3072, bias=False)
    )
  )
  (k_loras): ModuleList(
    (0): LoRALinearLayer(
      (down): Linear(in_features=3072, out_features=128, bias=False)
      (up): Linear(in_features=128, out_features=3072, bias=False)
    )
  )
  (v_loras): ModuleList(
    (0): LoRALinearLayer(
      (down): Linear(in_features=3072, out_features=128, bias=False)
      (up): Linear(in_features=128, out_features=3072, bias=False)
    )
  )
  (to_k_ip): Linear(in_features=4096, out_features=3072, bias=False)
  (to_v_ip): Linear(in_features=4096, out_features=3072, bias=False)
  (norm_added_k): RMSNorm()
), 'single_transformer_blocks.36.attn.processor': MultiSingleStreamBlockLoraProcessor(
  (q_loras): ModuleList(
    (0): LoRALinearLayer(
      (down): Linear(in_features=3072, out_features=128, bias=False)
      (up): Linear(in_features=128, out_features=3072, bias=False)
    )
  )
  (k_loras): ModuleList(
    (0): LoRALinearLayer(
      (down): Linear(in_features=3072, out_features=128, bias=False)
      (up): Linear(in_features=128, out_features=3072, bias=False)
    )
  )
  (v_loras): ModuleList(
    (0): LoRALinearLayer(
      (down): Linear(in_features=3072, out_features=128, bias=False)
      (up): Linear(in_features=128, out_features=3072, bias=False)
    )
  )
  (to_k_ip): Linear(in_features=4096, out_features=3072, bias=False)
  (to_v_ip): Linear(in_features=4096, out_features=3072, bias=False)
  (norm_added_k): RMSNorm()
), 'single_transformer_blocks.37.attn.processor': MultiSingleStreamBlockLoraProcessor(
  (q_loras): ModuleList(
    (0): LoRALinearLayer(
      (down): Linear(in_features=3072, out_features=128, bias=False)
      (up): Linear(in_features=128, out_features=3072, bias=False)
    )
  )
  (k_loras): ModuleList(
    (0): LoRALinearLayer(
      (down): Linear(in_features=3072, out_features=128, bias=False)
      (up): Linear(in_features=128, out_features=3072, bias=False)
    )
  )
  (v_loras): ModuleList(
    (0): LoRALinearLayer(
      (down): Linear(in_features=3072, out_features=128, bias=False)
      (up): Linear(in_features=128, out_features=3072, bias=False)
    )
  )
  (to_k_ip): Linear(in_features=4096, out_features=3072, bias=False)
  (to_v_ip): Linear(in_features=4096, out_features=3072, bias=False)
  (norm_added_k): RMSNorm()
)}